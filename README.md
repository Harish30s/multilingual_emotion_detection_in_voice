
# Multilingual Emotion Detection in Voice

This project focuses on detecting emotions from voice recordings across multiple languages using machine learning and signal processing techniques. It aims to enhance human-computer interaction by identifying emotional tone in speech, applicable in customer service, healthcare, and AI assistants.

 ğŸ“˜ Project Overview

The Jupyter Notebook implements a workflow for:
- Preprocessing audio files
- Extracting features (MFCCs, chroma, mel spectrograms)
- Building and training a machine learning model
- Predicting emotional tone from multilingual voice inputs

 ğŸ§  Features

- ğŸ™ï¸ Multilingual voice emotion detection
- ğŸ§¾ Feature extraction using `librosa`
- ğŸ› ï¸ Emotion classification with machine learning
- ğŸ“ˆ Visualization of dataset and model performance

 ğŸ—‚ï¸ Project Structure

```plaintext
multilingual_emotion_detection_in_voice.ipynb  # Main notebook
README.md                                      # Project documentation
````

 ğŸ“¦ Requirements

Install required Python packages:

```bash
pip install -r requirements.txt
```

**Key Dependencies:**

* `librosa`
* `numpy`
* `scikit-learn`
* `matplotlib`
* `pandas`
* `soundfile` or `pysoundfile`

 ğŸ’» Usage

1. Clone the repository or download the notebook.
2. Prepare your dataset of audio files with labeled emotions.
3. Run the notebook:

   ```bash
   jupyter notebook multilingual_emotion_detection_in_voice.ipynb
   ```
4. Follow the notebook instructions to preprocess data, extract features, train the model, and predict emotions.

 ğŸ“Š Emotions Supported

Examples (can be modified based on dataset):

* Happy
* Sad
* Angry
* Neutral
* Fear
* Disgust
* Surprise

 ğŸŒ Multilingual Support

* The model is trained/tested on multilingual audio samples.
* Add language-specific preprocessing if required.

 âš ï¸ Notes

* Audio files must be in a supported format (e.g., WAV).
* Background noise and low-quality recordings may affect performance.
 ğŸ“œ License

MIT License

---

 ğŸ‘¤ Author

[HARISH S]
